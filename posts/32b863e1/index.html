<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>MPI | Dasi's Blog</title><meta name="author" content="Dasi"><meta name="copyright" content="Dasi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="MPI 结构、梯形积分实现、集合通信、派生数据类型、奇偶换位排序"><meta property="og:type" content="article"><meta property="og:title" content="MPI"><meta property="og:url" content="https://dasi.plus/posts/32b863e1/"><meta property="og:site_name" content="Dasi&#39;s Blog"><meta property="og:description" content="MPI 结构、梯形积分实现、集合通信、派生数据类型、奇偶换位排序"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://dasi.plus/image/cover_parallel.webp"><meta property="article:published_time" content="2025-02-06T08:39:40.000Z"><meta property="article:modified_time" content="2025-03-05T07:27:38.235Z"><meta property="article:author" content="Dasi"><meta property="article:tag" content="并行程序"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://dasi.plus/image/cover_parallel.webp"><link rel="shortcut icon" href="/image/avatar.webp"><link rel="canonical" href="https://dasi.plus/posts/32b863e1/"><link rel="preconnect"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css?v=6.5.1"><link rel="stylesheet" href="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.css?v=5.0.33" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:8,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:300},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:250,languages:{author:"作者: Dasi",link:"链接: ",source:"来源: Dasi's Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"/pluginsSrc/@egjs/infinitegrid/dist/infinitegrid.min.js?v=4.11.1",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyload:!0,isAnchor:!1,percent:{toc:!1,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"MPI",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2025-03-05 15:27:38"}</script><link rel="stylesheet" href="APlayer.min.css"><div id="aplayer"></div><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js" async></script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/tag.css?1"><link rel="stylesheet" href="/css/nav.css?1"><link rel="stylesheet" href="/css/homeArticle.css?1"><link rel="stylesheet" href="/css/category.css?1"><link rel="stylesheet" href="/css/cursor.css?1"><link rel="stylesheet" href="/css/background.css?1"><link rel="stylesheet" href="/css/rightmenu.css?1"><link rel="stylesheet" href="/css/copyright.css?1"><link rel="stylesheet" href="/css/archive.css?1"><link rel="stylesheet" href="/css/description.css?1"><link rel="stylesheet" href="/css/post.css?1"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/avatar.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">79</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i> <span>博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-star"></i> <span>生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page child" href="/travel/"><i class="fa-fw fas fa-globe"></i> <span>旅游</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('/image/cover_parallel.webp')"><nav id="nav"><span id="blog-info"><a href="/" title="Dasi's Blog"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/avatar.webp"><span class="site-name">Dasi's Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i> <span>博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-star"></i> <span>生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page child" href="/travel/"><i class="fa-fw fas fa-globe"></i> <span>旅游</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MPI</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2025-02-06T08:39:40.000Z" title="发表于 2025-02-06 16:39:40">2025-02-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>23分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="MPI"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><meta name="referrer" content="no-referrer"><h2 id="1-基本结构">1. 基本结构</h2><h3 id="1-1-终端命令">1.1 终端命令</h3><p><strong>消息传递接口（Message-Passing Interface, MPI）</strong>：定义了一种可以被 C 和 C++ 程序调用的函数库，而不是一种新的语言，它主要用于<strong>分布式内存系统</strong>中进程之间的通信，通过<strong>显式地发送和接收消息</strong>来实现数据交换。</p><p><code>mpi.h</code>：包含了所有 MPI 函数的声明和常量定义，在编写 MPI 程序时，需要在源代码中通过 <code>#include &lt;mpi.h&gt;</code> 引入该头文件</p><p><code>mpicc</code>：是 MPI 提供的 C 语言编译器包装器，封装了调用系统中标准编译器（如 gcc 或 clang）的过程，并自动添加 MPI 头文件和库的搜索路径，编译 MPI 程序时通常使用 <code>mpicc -o my_program my_program.c</code></p><p><code>mpiexec</code>：用于启动 MPI 程序，负责在一个或多个节点上启动多个 MPI 进程，并建立进程间的通信环境，运行 MPI 程序时通常使用 <code>mpiexec -n 4 ./my_program</code></p><h3 id="1-2-基本框架">1.2 基本框架</h3><p>初始化 MPI 环境：当程序不适用参数时，可以简单设置为 NULL，函数返回程序错误码，在这之前不应该调用任何 MPI 函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">MPI_Init</span><span class="params">(</span></span><br><span class="line"><span class="params">  <span class="type">int</span>*    argc_p,</span></span><br><span class="line"><span class="params">  <span class="type">char</span>*** argv_p</span></span><br><span class="line"><span class="params">)</span>;</span><br></pre></td></tr></table></figure><p>关闭 MPI 环境并释放资源：在这之后不应该调用任何 MPI 函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">MPI_Finalize</span><span class="params">(<span class="type">void</span>)</span>;</span><br></pre></td></tr></table></figure><h3 id="1-3-通信子">1.3 通信子</h3><p><strong>通信子（communicator）</strong>：是 MPI 中管理和组织进程通信的基本单位，用于定义了一个<strong>通信范围=进程组+通信上下文</strong></p><ul><li><strong>进程组</strong>：明确了参与该通信的所有进程，只有属于同一通信子的进程才能直接进行通信</li><li><strong>通信上下文</strong>：保证消息隔离，确保了不同通信子之间的消息不会互相干扰，即使消息的标签、数据类型等相同</li></ul><p><code>MPI_COMM_WORLD</code>：默认通信子，包括了启动程序时的所有进程</p><p>通信子操作</p><ol><li><code>MPI_Comm_dup(MPI_COMM_WORLD, &amp;new_comm);</code>：复制一个已有的通信子，复制后的通信子<strong>拥有相同的进程组，但会获得一个新的上下文</strong>，从而保证与原通信子中的消息互不干扰</li><li><code>MPI_Comm_split(MPI_COMM_WORLD, color, key, &amp;new_comm);</code>：根据提供的**颜色（color）和关键字（key）**参数，将一个通信子划分为多个新的通信子</li><li><code>MPI_Comm_create(MPI_COMM_WORLD, group, &amp;new_comm);</code>：根据一个进程组创建一个新的通信子，只包含指定组中的进程</li><li><code>MPI_Comm_free(&amp;comm);</code>：释放通信子占用的资源</li><li><code>int MPI_Comm_size(MPI_Comm comm, int *size);</code>：获取指定通信子中包含的进程总数</li><li><code>int MPI_Comm_rank(MPI_Comm comm, int *rank);</code>：获取当前进程在指定通信子中的编号，编号范围通常从 0 到 size - 1</li></ol><h3 id="1-4-SPMD-模式">1.4 SPMD 模式</h3><p><strong>单程序多数据模式（Single Program Multiple Data, SPMD）</strong>：是一种常见的并行编程范式，其基本思想是所有参与并行计算的进程或线程都运行同一份程序代码，但<strong>每个进程或线程根据自己的标识处理不同的数据子集或执行不同的任务</strong></p><ul><li>灵活的数据分配：通过进程标识，可以灵活地将大数据集划分为多个子集，并由不同进程独立处理</li><li>维护简单：所有参与计算的进程运行同一份代码</li><li>良好的扩展性：只需调整数据划分或通信策略，程序整体结构基本不变</li></ul><div class="note success flat"><p>通常来说，利用<code>if-else</code>结构来区分主进程负责数据汇总、调度和 I/O 操作，而其他进程 则负责具体的计算或数据处理工作</p></div><h3 id="1-5-MPI-Send-和-MPI-Recv">1.5 MPI_Send 和 MPI_Recv</h3><p><code>int MPI_Send(const void *msg_buf_p, int msg_size, MPI_Datatype msg_type, int dest, int tag, MPI_Comm comm);</code>：将数据从发送进程传送给目标进程，是阻塞式的即当且仅当数据已被复制到内部缓冲区或目标进程已开始接收数据才返回</p><ul><li>msg_buf_p：指向待发送数据的缓冲区的指针</li><li>msg_size：待发送数据中元素的数量</li><li>msg_type：数据类型</li><li>dest：目标进程在指定通信子中的编号</li><li>tag：消息标签，用于标识消息</li><li>comm：通信子</li></ul><p><code>int MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status);</code>：用于接收来自其他进程发送的数据，是阻塞式的即当且仅当数据完全接收到并放入指定缓冲区后才返回</p><ul><li>msg_buf_p：指向接收数据的缓冲区的指针</li><li>buf_size：接收数据中最大允许存储的元素数量</li><li>buf_type：数据类型</li><li>tag：消息标签，用于标识消息</li><li>comm：通信子</li><li>status_p：返回接收状态信息的结构体指针，可以用来查询实际接收的数据量、来源、标签等</li></ul><p>匹配条件</p><ol><li><strong>通信子相同</strong>：处于同一通信域内</li><li><strong>消息标签相同</strong>：发送操作使用的标签必须与接收操作中指定的标签相等</li><li><strong>消息标识匹配</strong>：接收操作中指定的 source 和发送操作中的 dest 必须对应</li><li><strong>数据类型一致</strong>：发送的数据类型 msg_type 必须与接收端缓冲区预期的数据类型 buf_type 一致</li><li><strong>消息大小不超过接收缓冲区</strong>：发送的数据大小 msg_size 必须小于等于接收端缓冲区的大小 buf_size</li></ol><p>通配符：特殊关键字 <code>MPI_ANY_SOURCE</code> 和 <code>MPI_ANY_TAG</code>，使得接收端可以接收任意来源和标签的消息</p><p>MPI_Status：作为一个结构体，是 MPI_Recv 函数中的最后一个参数，当使用通配符时，通过 status 参数可以<strong>查明实际匹配到的发送进程和消息标签</strong>，具有数据成员 MPI_SOURCE、MPI_TAG 和 MPI_ERROR</p><div class="note warning flat"><p>阻塞的影响</p><ul><li>消息是<strong>不可超越的</strong>，即对于同一个发送者向同一个接收者发送的消息，如果它们使用相同的通信子、标签和匹配条件，那么接收者必定以发送顺序接收到这些消息，而不会出现后发送的消息先到的情况</li><li>进程悬挂，即如果进程调用了 MPI_Recv 但没有匹配的 MPI_Send，或者调用了 MPI_Send 但没有匹配的 MPI_Recv，则进程会被无限阻塞</li></ul></div><h2 id="2-用-MPI-实现梯形积分法">2. 用 MPI 实现梯形积分法</h2><h3 id="2-1-伪代码">2.1 伪代码</h3><p>梯形面积和 =<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo stretchy="false">[</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>2</mn><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo>…</mo><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">h[f(x_0) / 2 + f(x_1) + \ldots + f(x_{n-1} + f(x_n) / 2)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">h</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/2</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6667em;vertical-align:-.0833em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/2</span><span class="mclose">)]</span></span></span></span></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Parallel/202502272001123.png" alt=""></p><p>串行程序伪代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">h = (b-a) / n</span><br><span class="line">approx = ( f(a) + f(b)) / 2</span><br><span class="line">for (i = 1; i &lt;= n-1; i++) &#123;</span><br><span class="line">  x_i = a + i * h</span><br><span class="line">  approx += f(x_i)</span><br><span class="line">&#125;</span><br><span class="line">approx = h * approx</span><br></pre></td></tr></table></figure><p>并行程序伪代码（假设有k个核，划分为n个梯形）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Get a, b, n;</span><br><span class="line">h = (b - a) / n;</span><br><span class="line">local_n = n / k;</span><br><span class="line">local_a = a + rank * local_n * h</span><br><span class="line">local_b = local_a + local_n * h</span><br><span class="line">local_integral = Trap(local_a, local_b, local_n, h)</span><br><span class="line">if (rank != 0)</span><br><span class="line">  Send local_integral to Process0</span><br><span class="line">else &#123;</span><br><span class="line">  total_integral = local_integral</span><br><span class="line">  for (proc = 1; proc &lt; k; proc++)&#123;</span><br><span class="line">    Recv local_integral from proc</span><br><span class="line">    total_integral += local_integral</span><br><span class="line">  &#125;</span><br><span class="line">if (rank == 0)</span><br><span class="line">  print result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-I-O-处理">2.2 I/O 处理</h3><p>输出存在的问题：如果多个进程试图写标准输出stdout，那么这些进程的输出顺序是无法预测的，每次运行的顺序都可能不同</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Parallel/202502272001124.png" alt=""></p><p>输入存在的问题：大部分 MPI 只允许 0 号进程访问标准输入 stdin，因此 0 号进程还需要将输入数据发送到其他进程</p><p>输出缓冲区问题：如果要输出其他提示信息，必须添加换行符，因为 stdout 只有在遇到换行符或者缓冲区满时，才会真正把数据刷新到屏幕上</p><h3 id="2-3-代码">2.3 代码</h3><p>算法流程</p><ol><li>并行划分：将总的梯形数 n 分成 k 份</li><li>局部计算：每个进程独立计算其区间上的积分制</li><li>消息传递：非主进程将计算结果发送到主进程</li><li>结果输出：主进程汇总全部计算结果，输出积分结果</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mpi.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 假设原函数为 f(x) = x^2，计算从 local_a 到 local_b，次数为 local_n，步长为 h 的梯形积分</span></span><br><span class="line"><span class="type">double</span> <span class="title function_">calcIntegral</span><span class="params">(<span class="type">double</span> local_a, <span class="type">double</span> local_b, <span class="type">int</span> local_n, <span class="type">double</span> h)</span> &#123;</span><br><span class="line">    <span class="type">double</span> estimate = <span class="number">0.0</span>, x_i;</span><br><span class="line">    estimate = (local_a*local_a + local_b*local_b) / <span class="number">2.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; local_n; i++) &#123;</span><br><span class="line">        x_i = local_a + i * h;</span><br><span class="line">        estimate += x_i * x_i;</span><br><span class="line">    &#125;</span><br><span class="line">    estimate = estimate * h;</span><br><span class="line">    <span class="keyword">return</span> estimate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取输入</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">getInput</span><span class="params">(<span class="type">int</span> my_rank, <span class="type">int</span> comm_sz, <span class="type">double</span>* a_p, <span class="type">double</span>* b_p, <span class="type">int</span>* n_p)</span> &#123;</span><br><span class="line">    <span class="type">int</span> dest;</span><br><span class="line">    <span class="keyword">if</span> (my_rank == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Enter a, b, and n:\n&quot;</span>);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%lf %lf %d&quot;</span>, a_p, b_p, n_p);</span><br><span class="line">        <span class="keyword">for</span> (dest = <span class="number">1</span>; dest &lt; comm_sz; dest++) &#123;</span><br><span class="line">            MPI_Send(a_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(b_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(n_p, <span class="number">1</span>, MPI_INT, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        MPI_Recv(a_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(b_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(n_p, <span class="number">1</span>, MPI_INT, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">    <span class="type">int</span> comm_sz;</span><br><span class="line">    <span class="type">int</span> my_rank;</span><br><span class="line">    </span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取积分区间和次数</span></span><br><span class="line">    <span class="type">double</span> a, b;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    getInput(my_rank, comm_sz, &amp;a, &amp;b, &amp;n);</span><br><span class="line">    <span class="type">double</span> h = (b - a) / (<span class="type">double</span>)n;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据进程编号计算当前进程负责的积分区间</span></span><br><span class="line">    <span class="type">double</span> local_n = n / comm_sz;</span><br><span class="line">    <span class="type">double</span> local_a = a + my_rank * local_n * h;</span><br><span class="line">    <span class="type">double</span> local_b = local_a + local_n * h;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算局部积分</span></span><br><span class="line">    <span class="type">double</span> local_integral = calcIntegral(local_a, local_b, local_n, h);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Process %d of %d gets local_integral %.2f\n&quot;</span>, my_rank, comm_sz, local_integral);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果当前进程不是主进程，将局部积分发送到主进程</span></span><br><span class="line">    <span class="keyword">if</span> (my_rank != <span class="number">0</span>) &#123;</span><br><span class="line">        MPI_Send(&amp;local_integral, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 主进程从其他进程接收局部积分，并累加计算总积分，最后输出</span></span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">double</span> total_integral = local_integral;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> proc = <span class="number">1</span>; proc &lt; comm_sz; proc++) &#123;</span><br><span class="line">            <span class="type">double</span> temp_integral;</span><br><span class="line">            MPI_Recv(&amp;temp_integral, <span class="number">1</span>, MPI_DOUBLE, proc, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">            total_integral += temp_integral;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Estimate of the integral from %lf to %lf = %.15e\n&quot;</span>, a, b, total_integral);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-集合通信">3. 集合通信</h2><p><strong>点到点通信（point-to-point）</strong>：单个发送进程与单个接收进程之间的通信，如 MPI_Send 和 MPI_Recv</p><p>树形结构通信：是点到点通信的变种，<strong>将汇总任务分散到不同进程节点上</strong>，而主进程负责将全部子汇总任务的结果汇总</p><div class="note success flat"><p>如果是 0 号进程负责全部汇总，那么需要进行 7 次接收和 7 次加法，而使用树形结构通信，0 号进程只需要 3 次接收和 3 次加法<br>如果全部进程是同时启动的，那么前者需要 7 个时间量，而后者只需要 3 个时间量，减少了超过 50% 的总时间！</p></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Parallel/202502272001125.png" alt=""></p><p><strong>集合通信（collective）</strong>：通信子中的所有进程都参与到通信中，而不需要指定单一发送方和接收方</p><h3 id="3-1-MPI-Reduce">3.1 MPI_Reduce</h3><p>MPI_Reduce：将通信子中<strong>所有进程的数据按照某种归约操作合并</strong>，并将结果发送给指定进程</p><ul><li><code>sendbuf</code>：指向发送缓冲区的指针，包含了本进程要参加归约操作的数据</li><li><code>recvbuf</code>：指向接收缓冲区的指针，存放归约操作后的结果</li><li><code>count</code>：参与归约的数据个数</li><li><code>datatype</code>：数据类型</li><li><code>op</code>：归约操作符</li><li><code>root</code>：归约结果存放的根进程编号</li><li><code>comm</code>：通信子，规定了归约操作的进程范围</li></ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Parallel/202502272001126.png" alt=""></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对所有进程的值进行求最大值和求和操作</span></span><br><span class="line"><span class="type">int</span> local_value, global_max, global_sum;</span><br><span class="line">MPI_Reduce(&amp;local_value, &amp;global_max, <span class="number">1</span>, MPI_INT, MPI_MAX, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">MPI_Reduce(&amp;local_value, &amp;global_sum, <span class="number">1</span>, MPI_DOUBLE, MPI_SUM, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对数组的每个分量进行求累乘积操作</span></span><br><span class="line"><span class="type">double</span> local_value[N], prod[N];</span><br><span class="line">MPI_Reduce(local_value, prod, N, MPI_DOUBLE, MPI_PROD, <span class="number">0</span>, MPI_COMM_WORLD);</span><br></pre></td></tr></table></figure><p>注意事项</p><ol><li>所有进程必须调用相同的集合通信函数</li><li>每个进程传递给 MPI 集合通信函数的参数必须是相容的，即 count，root 等参数应该相同，否则会导致错误或未定义行为</li><li>只有根进程需要接收归约后的全局结果参数，即recv_buf 只能用在 root 上，其他进程只需要提供占位参数</li><li>不允许使用同一个缓冲区同时是输入缓冲和输出缓冲，这样的结果是不可预测的</li></ol><p><code>MPI_AllReduce</code>：相比于 <code>MPI_Reduce</code>，少了 root 参数，且允许全部进程都设置 recv_buf 参数，也就是说所有进程都可以得到归约结果</p><h3 id="3-2-MPI-Bcast">3.2 MPI_Bcast</h3><p>MPI_Bcast：用于<strong>将某个进程中的数据发送给通信子内所有进程</strong>，常用于分发输入参数、配置数据、或者初始条件等</p><ul><li><code>recv_buf</code>：存放广播数据的缓冲区</li><li><code>count</code>：要广播的数据元素个数</li><li><code>datatype</code>：要广播的数据类型</li><li><code>root</code>：根进程编号，数据源头</li><li><code>comm</code>：通信子，指定参与广播的进程组</li></ul><p>对上述 <code>getInput</code> 函数的一个改进</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">getInput</span><span class="params">(</span></span><br><span class="line"><span class="params">      <span class="type">int</span> my_rank,</span></span><br><span class="line"><span class="params">      <span class="type">int</span> comm_sz,</span></span><br><span class="line"><span class="params">      <span class="type">double</span>* a_p,</span></span><br><span class="line"><span class="params">      <span class="type">double</span>* b_p,</span></span><br><span class="line"><span class="params">      <span class="type">double</span>* n_p)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (my_rank == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Enter a, b and n \n&quot;</span>);</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%lf %lf %d&quot;</span>, a_p, b_p, n_p);</span><br><span class="line">  &#125;</span><br><span class="line">  MPI_Bcast(a_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">  MPI_Bcast(b_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">  MPI_Bcast(n_p, <span class="number">1</span>, MPI_INT, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-3-MPI-Scatter">3.3 MPI_Scatter</h3><p>数据分发</p><table><thead><tr><th>方式</th><th>定义</th><th>特点</th></tr></thead><tbody><tr><td>块划分</td><td>将数据或任务划分成<strong>连续区间的多个块</strong>，每个进程负责处理其中一个块</td><td>数据局部性好，但是可能导致负载不均</td></tr><tr><td>循环划分</td><td>按照<strong>轮询</strong>的方式将数据轮流分配给各个进程</td><td>数据局部性差，负载均衡</td></tr><tr><td>块循环划分</td><td>先将数据划分成若干小块，然后将这些块按照循环方式分配给各进程</td><td>兼顾数据局部性与负载均衡，可以根据问题特性选择合适的块大小</td></tr></tbody></table><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Parallel/202502272001128.png" alt=""></p><p>MPI_Scatter：相当于块划分，用于将进程的数据缓冲区中的数据<strong>按进程数量等分</strong>，然后将每一份数据分散到通信子中的所有进程的接收缓冲区中进行处理</p><ul><li><code>send_buf</code>：指向发送缓冲区的指针，仅在根进程上有效</li><li><code>send_count</code>：发送数据的个数</li><li><code>send_type</code>：发送数据的数据类型</li><li><code>recv_buf</code>：指向接收缓冲区的指针</li><li><code>recv_count</code>：接收数据的个数</li><li><code>recv_type</code>：接收数据的数据类型</li><li><code>root</code>：根进程编号</li><li><code>comm</code>：通信子，指定参与分散操作的进程集合</li></ul><p>假设根进程有一个包含 20 个整数的数组，分散给 4 个进程处理加法（包括自己），则每个进程接收 5 个整数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mpi.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">    <span class="type">int</span> comm_sz, rank;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> root = <span class="number">0</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = <span class="number">20</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> count = <span class="number">5</span>;</span><br><span class="line">    <span class="type">int</span> sendbuf[n];</span><br><span class="line">    <span class="type">int</span> recvbuf[count];</span><br><span class="line">    </span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rank == root) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            sendbuf[i] = i + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MPI_Scatter(sendbuf, count, MPI_INT,</span><br><span class="line">                recvbuf, count, MPI_INT,</span><br><span class="line">                root, MPI_COMM_WORLD);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> local_sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; sendcount; i++) &#123;</span><br><span class="line">      local_sum += recvbuf[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Process %d gets sum %d\n&quot;</span>, rank, local_sum);</span><br><span class="line"></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-4-MPI-Gather">3.4 MPI_Gather</h3><p>MPI_Gather：相当于块聚集，将每个进程中的数据收集到根进程上，并将这些数据放在一个连续的缓冲区中</p><ul><li><code>send_buf</code>：指向发送缓冲区的指针</li><li><code>send_count</code>：发送数据的个数</li><li><code>send_type</code>：发送数据的类型</li><li><code>recv_buf</code>：指向接收缓冲区的指针，仅在根进程上有效</li><li><code>recv_count</code>：接收数据的个数</li><li><code>recv_type</code>：接收数据的类型</li><li><code>root</code>：根进程编号</li><li><code>comm</code>：通信子，指定了参与操作的进程组</li></ul><div class="note warning flat"><p>根据 MPI 标准，聚集结果是按照进程的 rank 顺序排列的</p></div><p>打印分布式向量：每个进程传递一个数据给主进程，主进程聚集所有进程数据然后输出</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Print_vector</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">double</span> local_b[],</span></span><br><span class="line"><span class="params">    <span class="type">int</span> local_n,</span></span><br><span class="line"><span class="params">    <span class="type">int</span> n,</span></span><br><span class="line"><span class="params">    <span class="type">char</span> title[],</span></span><br><span class="line"><span class="params">    <span class="type">int</span> my_rank,</span></span><br><span class="line"><span class="params">    MPI_Comm comm</span></span><br><span class="line"><span class="params">)</span> &#123;</span><br><span class="line">  <span class="type">double</span>* b = <span class="literal">NULL</span>;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">  <span class="keyword">if</span> (my_rank == <span class="number">0</span>) &#123;</span><br><span class="line">    b = <span class="built_in">malloc</span>(n * <span class="keyword">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    MPI_Gather(local_b, local_n, MPI_DOUBLE, b, local_n, MPI_DOUBLE, <span class="number">0</span>, comm);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, title);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%f &quot;</span>, b[i]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">free</span>(b);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    MPI_Gather(local_b, local_n, MPI_DOUBLE, b, local_n, MPI_DOUBLE, <span class="number">0</span>, comm);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MPI_Allgather：相比于 MPI_Gather，没有了根进程，因为所有进程都可以获得聚集结果</p><p>矩阵-向量乘法：计算 y 的行分量时，需要 A 的一个行分量，但需要 x 的全部行分量</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Parallel/202502272001129.png" alt=""></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Mat_vect_mult</span><span class="params">(</span></span><br><span class="line"><span class="params">  <span class="type">double</span> local_A[], <span class="comment">// 当前进程拥有的矩阵 A 的部分行</span></span></span><br><span class="line"><span class="params">  <span class="type">double</span> local_x[], <span class="comment">// 当前进程拥有的向量 x 的部分行</span></span></span><br><span class="line"><span class="params">  <span class="type">double</span> local_y[], <span class="comment">// 存放当前进程计算得到的结果向量 y 的对应部分</span></span></span><br><span class="line"><span class="params">  <span class="type">int</span> local_m, <span class="comment">// 当前进程获得的矩阵 A 的行数</span></span></span><br><span class="line"><span class="params">  <span class="type">int</span> local_n, <span class="comment">// 当前进程获得的向量 x 的行数</span></span></span><br><span class="line"><span class="params">  <span class="type">int</span> n,       <span class="comment">// 矩阵 A 的总列数，向量 x 的总行数 </span></span></span><br><span class="line"><span class="params">  MPI_Comm comm)</span> &#123;</span><br><span class="line">    <span class="type">double</span>* x; <span class="comment">// 局部变量，存放收集到的完整向量 x</span></span><br><span class="line">    x = <span class="built_in">malloc</span>(n * <span class="keyword">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    MPI_Allgather(local_x, local_n, MPI_DOUBLE, x, local_n, MPI_DOUBLE, comm);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i, j;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; local_m; i++) &#123;</span><br><span class="line">      local_y[i] = <span class="number">0.0</span>;</span><br><span class="line">      <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">        local_y[i] += local_A[i * n + j] * x[j];</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="built_in">free</span>(x);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="4-派生数据类型">4. 派生数据类型</h2><p>派生数据类型：由一系列的 MPI 基本数据类型和每个数据类型的偏移所组成的</p><ul><li>在 MPI 中，<strong>消息的发送和接收通常存在较高的时间成本</strong>，与其将基础数据类型分多次发送，不如将多个基础数据组合成一个派生数据类型一次性发送，这样可以减少通信次数和启动开销，从而提高性能</li><li>如果不使用派生数据类型，必须手动将非连续的数据打包到一个连续的缓冲区中，然后传输，接收端再拆包，不仅编程麻烦，而且可能增加额外的内存和时间开销</li></ul><p>MPI_Type_contiguous：创建由相同类型的数据块组成的派生数据类型</p><ul><li><code>count</code>：连续元素的数量</li><li><code>datatype</code>：基础数据类型</li><li><code>new_type_p</code>：指向新数据类型的数据的起始位置的指针</li></ul><p>MPI_Type_create_struct：创建一个由不同类型的数据块组成的派生数据类型</p><ul><li><code>count</code>：不同数据块的数量</li><li><code>array_of_lengths</code>：每个数据块中的数据数量</li><li><code>array_of_offsets</code>：每个数据块在结构体中相对于起始位置的字节偏移</li><li><code>array_of_types</code>：每个数据块中数据的基础数据类型</li><li><code>new_type_p</code>：指向新数据类型的数据的起始位置的指针</li></ul><p>要用到的其他函数</p><ul><li><code>int MPI_Get_address(const void *location, MPI_Aint *address)</code>：用于获取某个变量或结构体成员在内存中的绝对地址，存储在类型为 MPI_Aint 的变量中，在创建派生数据类型时用于<strong>计算关于起始地址的偏移量</strong></li><li><code>int MPI_Type_commit(MPI_Datatype *datatype)</code>：将一个新创建的派生数据类型提交给 MPI 系统，使其准备好供通信操作使用</li><li><code>int MPI_Type_free(MPI_Datatype *datatype)</code>：释放一个已提交的派生数据类型所占用的资源</li></ul><p>主进程一次性传递数据到其他进程</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">spreadData</span><span class="params">(<span class="type">double</span>* a_p, <span class="type">double</span>* b_p, <span class="type">int</span>* c_p)</span> &#123;</span><br><span class="line">  <span class="comment">// 设置派生数据类型的基础信息</span></span><br><span class="line">  <span class="type">int</span> count = <span class="number">3</span>;</span><br><span class="line">  <span class="type">int</span> lengths[<span class="number">3</span>] = &#123;<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">  MPI_Aint offsets[<span class="number">3</span>];</span><br><span class="line">  MPI_Datatype types[<span class="number">3</span>] = &#123;MPI_DOUBLE, MPI_DOUBLE, MPI_INT&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取成员地址及其偏移量</span></span><br><span class="line">  MPI_Aint a_addr, b_addr, c_addr;</span><br><span class="line">  MPI_Get_address(a_p, &amp;a_addr);</span><br><span class="line">  MPI_Get_address(b_p, &amp;b_addr);</span><br><span class="line">  MPI_Get_address(c_p, &amp;c_addr);</span><br><span class="line">  offsets[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">  offsets[<span class="number">1</span>] = b_addr - a_addr;</span><br><span class="line">  offsets[<span class="number">2</span>] = c_addr - a_addr;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 创建派生数据类型</span></span><br><span class="line">  MPI_Datatype new_struct;</span><br><span class="line">  MPI_Type_create_struct(count, lengths, offsets, types, &amp;new_struct);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 提交派生数据类型</span></span><br><span class="line">  MPI_Type_commit(&amp;new_struct);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 广播派生数据类型</span></span><br><span class="line">  MPI_Bcast(a_p, <span class="number">1</span>, new_struct, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 释放派生数据类型</span></span><br><span class="line">  MPI_Type_free(&amp;new_struct);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-性能评估">5. 性能评估</h2><h3 id="5-1-计时">5.1 计时</h3><p>几种时间</p><ul><li><strong>程序运行时间</strong>：从程序开始运行（MPI_INIT）到结束运行（MPI_Finalize）所耗费的时间，用来衡量整个程序包括初始化、通信、I/O 和计算等各部分的耗时</li><li><strong>CPU时间</strong>：程序实际<strong>占用 CPU 执行指令</strong>的时间，不包括程序等待 I/O 或其他系统资源的时间</li><li><strong>并行计算时间</strong>：所有进程共同进行并行计算部分所花费的时间，整个并行计算的完成时间取决于<strong>最慢的进程</strong></li></ul><p>相关函数</p><ul><li><code>double MPI_Wtime(void)</code>：返回一个双精度浮点数，表示当前的墙上时钟时间</li><li><code>int MPI_Barrier(MPI_Comm comm)</code>：用于同步所有进程，使通信子中所有进程在此调用处等待，直到所有进程都到达该调用点为止，然后再继续向下执行</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> local_start, local_finish, local_elapsed, global_elapsed;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 初始化部分 */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 同步进程，确保所有进程的开始时间相同</span></span><br><span class="line">MPI_Barrier(comm);   </span><br><span class="line">local_start = MPI_Wtime();</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 并行运算部分 */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取当前进程的耗时</span></span><br><span class="line">local_finish = MPI_Wtime();</span><br><span class="line">local_elapsed = local_finish - local_start;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取最慢进程的耗时作为整个并行程序的耗时</span></span><br><span class="line">MPI_Reduce(&amp;local_elapsed, &amp;global_elapsed, <span class="number">1</span>, MPI_DOUBLE, MPI_MAX, <span class="number">0</span>, comm);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 主进程输出计时结果</span></span><br><span class="line"><span class="keyword">if</span> (my_rank == <span class="number">0</span>)</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Elapsed time = %e seconds\n&quot;</span>, global_elapsed);</span><br></pre></td></tr></table></figure><div class="note warning flat"><p>由于操作系统的不可预知性，同一段程序的运行时间不可能每次都完全一样</p></div><h3 id="5-2-影响因素分析">5.2 影响因素分析</h3><p>由下表，我们可以得到以下规律</p><ol><li>随着进程数量 p 增加，运行时间下降</li><li>随着问题规模 n 增加，运行时间上升</li><li>当问题规模较小且进程数量足够多的时候，增加进程数量不会使得运行时间显著下降，这是因为此时进程间通信开销增大</li><li>在进程数量 p 较小，问题规模 n 较大的情况下，近似线性效率；在进程数量 p 较大，问题规模 n 较小的情况下，远远达不到线性效率</li></ol><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Parallel/202502272001131.png" alt=""></p><p>扩展性：当问题规模或资源数量发生变化时，系统能否保持原先较好的性能</p><ul><li>强扩展性：在不需要增加进程数量的前提下，增加问题规模依然能够保持恒定效率</li><li>弱扩展性：增加问题规模后，需要增加进程数量来维持恒定效率</li></ul><h2 id="6-并行奇偶换位排序算法">6. 并行奇偶换位排序算法</h2><p>原理：<strong>反复交替执行两个阶段来排序</strong>，每个阶段内的比较和交换操作彼此独立，因此可以并行执行</p><ul><li>奇数阶段：比较序列中索引为奇数的元素与其后面的相邻元素，如果前者大于后者，则交换</li><li>偶数阶段：比较序列中索引为偶数的元素与其后面的相邻元素，如果前者大于后者，则交换</li></ul><p>定理：<strong>如果序列有 n 个键值，那么经过 n 个阶段后，序列一定可以排好序</strong></p><div class="note success flat"><p>0起始：5，9，4，3<br>1偶数：5，9，3，4<br>2奇数：5，3，9，4<br>3奇数：3，5，4，9<br>4偶数：3，4，5，9</p></div><p>算法流程</p><ol><li>数据分发：主进程通过 MPI_Scatter 将待排序数组分发给各个进程</li><li>本地排序：每个进程对自己接收到的子数组进行本地排序</li><li>局部交换<ol><li>偶数阶段：如果进程号为偶数，则与右侧进程交换，否则与左侧进程交换</li><li>奇数阶段：如果进程号为奇数，则与右侧进程交换，否则与左侧进程交换</li><li>第一个进程可能没有左交换对象，最后一个进程可能没有右交换对象，可以设置 MPI_PROC_NULL 来避免产生无效通信</li></ol></li><li>合并数据：将两个局部有序数组合并，小编号进程保留小半部分，大编号进程保留大半部分</li><li>数据输出：主进程通过 MPI_Gather 得到全局排序结果</li></ol><p><code>MPI_Sendrecv</code>：当我们进行局部交换的时候，进程 x 发送消息等待进程 y 接收，而进程 y 也发送消息等待进程 x 接收，那么就会发生死锁，而 MPI_Sendrecv 会<strong>将发送和接收操作组合在一起，交给 MPI 库内部来协调这两个操作</strong>，不会出现死锁情况</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mpi.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 比较函数，用于 qsort 排序</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">compare_ints</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *a, <span class="type">const</span> <span class="type">void</span> *b)</span> &#123;</span><br><span class="line">    <span class="type">int</span> arg1 = *(<span class="type">const</span> <span class="type">int</span> *)a;</span><br><span class="line">    <span class="type">int</span> arg2 = *(<span class="type">const</span> <span class="type">int</span> *)b;</span><br><span class="line">    <span class="keyword">return</span> (arg1 &gt; arg2) - (arg1 &lt; arg2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 合并函数：合并两个数组为一个大数组，然后小半部分的数组给编号较小的进程</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">merge</span><span class="params">(<span class="type">int</span> *local_arr, <span class="type">int</span> *recv_arr, <span class="type">int</span> local_n, <span class="type">int</span> rank, <span class="type">int</span> partner)</span> &#123;</span><br><span class="line">    <span class="type">int</span> *temp = <span class="built_in">malloc</span>(<span class="number">2</span> * local_n * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, k = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; local_n &amp;&amp; j &lt; local_n) &#123;</span><br><span class="line">        <span class="keyword">if</span> (local_arr[i] &lt;= recv_arr[j])</span><br><span class="line">            temp[k++] = local_arr[i++];</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            temp[k++] = recv_arr[j++];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; local_n)</span><br><span class="line">        temp[k++] = local_arr[i++];</span><br><span class="line">    <span class="keyword">while</span> (j &lt; local_n)</span><br><span class="line">        temp[k++] = recv_arr[j++];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rank &lt; partner)</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; local_n; i++)</span><br><span class="line">            local_arr[i] = temp[i];</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; local_n; i++)</span><br><span class="line">            local_arr[i] = temp[i + local_n];</span><br><span class="line">    <span class="built_in">free</span>(temp);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">    <span class="type">int</span> size, rank;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = <span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> nums[N] = &#123;<span class="number">9</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">13</span>, <span class="number">19</span>, <span class="number">15</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">18</span>, <span class="number">17</span>, <span class="number">16</span>, <span class="number">10</span>&#125;;</span><br><span class="line"></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> local_n = N / size;</span><br><span class="line">    <span class="type">int</span>* local_nums = <span class="built_in">malloc</span>(local_n * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    <span class="type">int</span>* recv_nums = <span class="built_in">malloc</span>(local_n * <span class="keyword">sizeof</span>(<span class="type">int</span>)); </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 分发数据到每个进程的 local_nums 中</span></span><br><span class="line">    MPI_Scatter(nums, local_n, MPI_INT, local_nums, local_n, MPI_INT, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个进程对 local_nums 进行首次本地排序</span></span><br><span class="line">    qsort(local_nums, local_n, <span class="keyword">sizeof</span>(<span class="type">int</span>), compare_ints);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行 size 次奇偶交换排序</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> phase = <span class="number">0</span>; phase &lt; size; phase++) &#123;</span><br><span class="line">        <span class="type">int</span> partner;</span><br><span class="line">        <span class="comment">// 偶数阶段</span></span><br><span class="line">        <span class="keyword">if</span> (phase % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (rank % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">                partner = rank + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                partner = rank - <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 奇数阶段</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (phase % <span class="number">2</span> != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (rank % <span class="number">2</span> != <span class="number">0</span>)</span><br><span class="line">                partner = rank + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                partner = rank - <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断交换对象是否无效</span></span><br><span class="line">        <span class="keyword">if</span> (partner == <span class="number">-1</span> || partner == size)</span><br><span class="line">            partner = MPI_PROC_NULL;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 接发数据</span></span><br><span class="line">        MPI_Sendrecv(local_nums, local_n, MPI_INT, partner, <span class="number">0</span>, recv_nums, local_n, MPI_INT, partner, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 如果交换对象有效，则执行局部合并操作</span></span><br><span class="line">        <span class="keyword">if</span> (partner != MPI_PROC_NULL)</span><br><span class="line">            merge(local_nums, recv_nums, local_n, rank, partner);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 同步，保证所有进程都完成局部合并操作</span></span><br><span class="line">        MPI_Barrier(MPI_COMM_WORLD);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 收集每个进程的局部排序结果到主进程</span></span><br><span class="line">    MPI_Gather(local_nums, local_n, MPI_INT, nums, local_n, MPI_INT, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 主进程输出排序好的结果</span></span><br><span class="line">    <span class="keyword">if</span> (rank == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, nums[i]);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放动态分配的内存</span></span><br><span class="line">    <span class="built_in">free</span>(local_nums);</span><br><span class="line">    <span class="built_in">free</span>(recv_nums);</span><br><span class="line"></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>MPI</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://dasi.plus/posts/32b863e1/">https://dasi.plus/posts/32b863e1/</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a" style="display:inline-block;width:55px"><h>作者</h><div class="post-copyright-cc-info"><h>Dasi</h></div></div><div class="post-copyright-c" style="display:inline-block;width:105px"><h>发布于</h><div class="post-copyright-cc-info"><h>2025-02-06</h></div></div><div class="post-copyright-u" style="display:inline-block;width:105px"><h>更新于</h><div class="post-copyright-cc-info"><h>2025-03-05</h></div></div><div class="post-copyright-c" style="display:inline-block;width:98px"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY 4.0" href="https://creativecommons.org/licenses/by/4.0/deed.zh">CC BY 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F/">并行程序</a></div><div class="post_share"><div class="social-share" data-image="/image/cover_parallel.webp" data-sites="twitter,wechat,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css?v=1.1.3" media="print" onload='this.media="all"'><script src="/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js?v=1.1.3" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/c2e6ce0c/" title="Pthreads"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_parallel.webp" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Pthreads</div><div class="content">进程和线程、Pthreads 结构、竞争条件、路障、读写锁、缓存与线程安全</div></div></a></div><div class="next-post pull-right"><a href="/posts/d79b6007/" title="并行硬件和软件"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_parallel.webp" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">并行硬件和软件</div><div class="content">并行硬件、并行软件、并行性能、Foster 方法</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/d79b6007/" title="并行硬件和软件"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_parallel.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-06</div><div class="title">并行硬件和软件</div><div class="info">并行硬件、并行软件、并行性能、Foster 方法</div></div></a></div><div><a href="/posts/c2e6ce0c/" title="Pthreads"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_parallel.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-06</div><div class="title">Pthreads</div><div class="info">进程和线程、Pthreads 结构、竞争条件、路障、读写锁、缓存与线程安全</div></div></a></div><div><a href="/posts/d6137872/" title="OpenMP"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_parallel.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-06</div><div class="title">OpenMP</div><div class="info">OpenMP 结构、编译指令、归约子句、parallel for、调度方式、互斥机制</div></div></a></div></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="toc-text">1. 基本结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4"><span class="toc-text">1.1 终端命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%9F%BA%E6%9C%AC%E6%A1%86%E6%9E%B6"><span class="toc-text">1.2 基本框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E9%80%9A%E4%BF%A1%E5%AD%90"><span class="toc-text">1.3 通信子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-SPMD-%E6%A8%A1%E5%BC%8F"><span class="toc-text">1.4 SPMD 模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-MPI-Send-%E5%92%8C-MPI-Recv"><span class="toc-text">1.5 MPI_Send 和 MPI_Recv</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%94%A8-MPI-%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BD%A2%E7%A7%AF%E5%88%86%E6%B3%95"><span class="toc-text">2. 用 MPI 实现梯形积分法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E4%BC%AA%E4%BB%A3%E7%A0%81"><span class="toc-text">2.1 伪代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-I-O-%E5%A4%84%E7%90%86"><span class="toc-text">2.2 I&#x2F;O 处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E4%BB%A3%E7%A0%81"><span class="toc-text">2.3 代码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1"><span class="toc-text">3. 集合通信</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-MPI-Reduce"><span class="toc-text">3.1 MPI_Reduce</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-MPI-Bcast"><span class="toc-text">3.2 MPI_Bcast</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-MPI-Scatter"><span class="toc-text">3.3 MPI_Scatter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-MPI-Gather"><span class="toc-text">3.4 MPI_Gather</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%B4%BE%E7%94%9F%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-text">4. 派生数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="toc-text">5. 性能评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E8%AE%A1%E6%97%B6"><span class="toc-text">5.1 计时</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%BD%B1%E5%93%8D%E5%9B%A0%E7%B4%A0%E5%88%86%E6%9E%90"><span class="toc-text">5.2 影响因素分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E5%B9%B6%E8%A1%8C%E5%A5%87%E5%81%B6%E6%8D%A2%E4%BD%8D%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95"><span class="toc-text">6. 并行奇偶换位排序算法</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By Dasi</div><div class="footer_custom_text"><p><a style="margin-inline:5px" target="_blank" href="https://hexo.io/"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为 Hexo" alt="HEXO"></a><a style="margin-inline:5px" target="_blank" href="https://butterfly.js.org/"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用 Butterfly" alt="Butterfly"></a><a style="margin-inline:5px" target="_blank" href="https://github.com/"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由 GitHub 托管" alt="GitHub"></a></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa-solid fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa-solid fa-arrow-rotate-right"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa-solid fa-arrow-right"></i></a><a class="rightMenu-item" id="menu-radompage" href="javascript:window.location.href = window.location.origin;"><i class="fa-solid fa-house"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa-solid fa-copy"></i><span>复制</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();"><i class="fa-solid fa-circle-half-stroke"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();"><i class="fa-solid fa-book"></i><span>阅读模式</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa-solid fa-arrow-up"></i><span>置顶</span></a><a class="rightMenu-item" href="javascript:rmf.copyPageUrl();"><i class="fa-solid fa-link"></i><span>复制链接</span></a></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.umd.js?v=5.0.33"></script><script src="/pluginsSrc/instant.page/instantpage.js?v=5.2.0" type="module"></script><script src="/pluginsSrc/vanilla-lazyload/dist/lazyload.iife.min.js?v=17.8.8"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("/pluginsSrc/pangu/dist/browser/pangu.min.js?v=4.0.7").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><link rel="stylesheet" href="/pluginsSrc/katex/dist/katex.min.css?v=0.16.9"><script src="/pluginsSrc/katex/dist/contrib/copy-tex.min.js?v=0.16.9"></script><script>document.querySelectorAll("#article-container span.katex-display").forEach((a=>{btf.wrap(a,"div",{class:"katex-wrap"})}))</script><script>(()=>{const t=()=>{twikoo.init(Object.assign({el:"#twikoo-wrap",envId:"https://twikoo.dasi.net.cn/",region:"",onCommentLoaded:()=>{btf.loadLightbox(document.querySelectorAll("#twikoo .tk-content img:not(.tk-owo-emotion)"))}},null))},o=()=>{"object"==typeof twikoo?setTimeout(t,0):getScript("/pluginsSrc/twikoo/dist/twikoo.all.min.js?v=1.6.31").then(t)};btf.loadComment(document.getElementById("twikoo-wrap"),o)})()</script></div><script src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script><script src="/js/rightmenu.js?1"></script><script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script><script src="/js/rightside.js?1"></script><script src="/js/sitetitle.js?1"></script><script id="click-show-text" src="/pluginsSrc/butterfly-extsrc/dist/click-show-text.min.js?v=1.1.3" data-mobile="false" data-text="d,a,s,i" data-fontsize="20px" data-random="false" async></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var s=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),s.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/7bb01bb2/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_algorithm.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-10-22</span><a class="blog-slider__title" href="posts/7bb01bb2/" alt="">动态规划</a><div class="blog-slider__text">介绍了动态规划的原理，并用4个典例进行了详细分析，总结过后完成经典DP问题</div><a class="blog-slider__button" href="posts/7bb01bb2/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/46ae7d29/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_AI.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-04-28</span><a class="blog-slider__title" href="posts/46ae7d29/" alt="">α-β剪枝</a><div class="blog-slider__text">想一个默认描述好难的！</div><a class="blog-slider__button" href="posts/46ae7d29/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/f11dbe61/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_git.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-09-13</span><a class="blog-slider__title" href="posts/f11dbe61/" alt="">Git基本操作</a><div class="blog-slider__text">介绍git的基本操作以及对git指令的理解</div><a class="blog-slider__button" href="posts/f11dbe61/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/57fa915c/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_algorithm.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-10-14</span><a class="blog-slider__title" href="posts/57fa915c/" alt="">排序</a><div class="blog-slider__text">想一个默认描述好难的！</div><a class="blog-slider__button" href="posts/57fa915c/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/55f40959/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_AI.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-21</span><a class="blog-slider__title" href="posts/55f40959/" alt="">谓词逻辑的归结反演</a><div class="blog-slider__text">如何利用python实现谓词逻辑的归结反演，详细分析了每个函数</div><a class="blog-slider__button" href="posts/55f40959/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/bbea855c/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/cover_computernetwork.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-08-22</span><a class="blog-slider__title" href="posts/bbea855c/" alt="">运输层</a><div class="blog-slider__text">多路复用、多路分解、UDP和TCP、可靠数据传输原理、流水线模式和拥塞控制算法</div><a class="blog-slider__button" href="posts/bbea855c/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="/",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>